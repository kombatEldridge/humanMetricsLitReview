# humanMetricsLitReview
This is a repository made to hold the citations and notes on papers compiled for a literature review of metrics used to judge the "humanity" of a chatbot.

As Large Language Models (LLMs) have become publicly accessible, their use in popular culture will surely rise as their usefulness gains traction. A current LLM can often pass as human speech on first glance which can be dangerous. For example, this poses dangers to the school system as students begin to use LLMs to complete essay-based assignments. However, if used properly and announced ethically, the ability of an LLM to mimic human interaction can be useful. One such use is as a Non-Playable Character in a video game. Such roles require responses to a player's actions, but are typically limited behind a developer's generations before launch. LLMs could be used to produce more appropriately generated responses in real time. Through all these uses, a third-party may want to judge an LLM's ability to mimic human conversation. Here is a literature review on the methods and metrics by which current LLMs are judged on their humanity (hereto referred to as "humanity metrics").

## Metric Topics
### Engagement Metrics:
- **Conversation Length**: Measure the average length of conversations initiated by the chatbot. Longer conversations might indicate higher engagement.
  1. Neural Response Ranking for Social Conversation: A Data-Efficient Approach [[Paper]](https://aclanthology.org/W18-5701/)
  2. Enhancing Chat Language Models by Scaling High-quality Instructional Conversations [[Paper]](https://aclanthology.org/2023.emnlp-main.183/)
- **User Retention**: Track the percentage of users who return to interact with the chatbot again, indicating sustained engagement.
  1. Incorporating Politeness across Languages in Customer Care Responses: Towards building a Multi-lingual Empathetic Dialogue Agent [[Paper]](https://aclanthology.org/2020.lrec-1.514/)
  2. Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search [[Paper]](https://aclanthology.org/2023.acl-industry.73/)
  3. PoliSe: Reinforcing Politeness Using User Sentiment for Customer Care Response Generation [[Paper]](https://aclanthology.org/2022.coling-1.538/)

### Conversation Quality Metrics:
- **Coherence**: Assess the coherence and logical flow of the conversation. Incoherent responses can detract from the human-likeness.
  1. Coherence boosting: When your pretrained language model is not paying enough attention [[Paper]](https://aclanthology.org/2022.acl-long.565/)
  2. Optimizing Semantic Coherence in Topic Models [[Paper]](https://aclanthology.org/D11-1024/)
  3. Coherent or Not? Stressing a Neural Language Model for Discourse Coherence in Multiple Languages [[Paper]](https://aclanthology.org/2023.findings-acl.680/)
- **Context Sensitivity**: Determine how well the chatbot maintains context throughout the conversation, understanding and responding appropriately to previous inputs.
  1. Context Sensitivity Estimation in Toxicity Detection [[Paper]](https://aclanthology.org/2021.woah-1.15/)
  2. Context-sensitive evaluation of automatic speech recognition: considering user experience & language variation [[Paper]](https://aclanthology.org/2021.hcinlp-1.6/)
  3. Language Models as Context-sensitive Word Search Engines [[Paper]](https://aclanthology.org/2022.in2writing-1.5/)
  4. Learning Context-Aware Convolutional Filters for Text Processing [[Paper]](https://aclanthology.org/D18-1210)
  5. A Neural Network Approach to Context-Sensitive Generation of Conversational Responses [[Paper]](https://aclanthology.org/N15-1020)
- **Natural Language Understanding (NLU)**: Measure the accuracy of the chatbot in understanding the nuances of natural language inputs.
  1. GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding [[Paper]](https://aclanthology.org/W18-5446/)
  2. TinyBERT: Distilling BERT for Natural Language Understanding [[Paper]](https://aclanthology.org/2020.findings-emnlp.372/)
  3. Adversarial NLI: A New Benchmark for Natural Language Understanding [[Paper]](https://aclanthology.org/2020.acl-main.441/)
  4. Multi-Task Deep Neural Networks for Natural Language Understanding [[Paper]](https://aclanthology.org/P19-1441/)
- **Syntactic Correctness**: Evaluate the grammar and syntax of the responses generated by the chatbot.
  1. Human Evaluation of Creative NLG Systems: An Interdisciplinary Survey on Recent Papers [[Paper]](https://aclanthology.org/2021.gem-1.9/)
  2. Automatic Question Generation using Relative Pronouns and Adverbs [[Paper]](https://aclanthology.org/P18-3022/)
  3. Knowledge-enriched, Type-constrained and Grammar-guided Question Generation over Knowledge Bases [[Paper]](https://aclanthology.org/2020.coling-main.250/)
  4. Assessing Grammatical Correctness in Language Learning [[Paper]](https://aclanthology.org/2021.bea-1.15)
  5. Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency [[Paper]](https://aclanthology.org/P19-1103/)

### Human Likeness Metrics:
- **Emotional Intelligence**: Assess the chatbot's ability to recognize and respond empathetically to user emotions.
  1. Beyond Information: Is ChatGPT Empathetic Enough? [[Paper]](https://aclanthology.org/2023.ranlp-1.18/)
  2. Continuing Pre-trained Model with Multiple Training Strategies for Emotional Classification [[Paper]](https://aclanthology.org/2022.wassa-1.22)
  3. From Multilingual Complexity to Emotional Clarity: Leveraging Commonsense to Unveil Emotions in Code-Mixed Dialogues [[Paper]](https://aclanthology.org/2023.emnlp-main.598/)
  4. SOCIAL IQA: Commonsense Reasoning about Social Interactions [[Paper]](https://aclanthology.org/D19-1454)
  5. Modulating Language Models with Emotions [[Paper]](https://aclanthology.org/2021.findings-acl.379)
- **Personality**: Evaluate the chatbot's personality traits and how effectively they are conveyed through interactions.
  1. Manipulating the Perceived Personality Traits of Language Models [[Paper]](https://aclanthology.org/2023.findings-emnlp.156/)
  2. Controlling Personality-Based Stylistic Variation with Neural Natural Language Generators [[Paper]](https://aclanthology.org/W18-5019/)
  3. Building a Corpus for Personality-dependent Natural Language Understanding and Generation [[Paper]](https://aclanthology.org/L18-1183/)
  4. PERSONAGE: Personality Generation for Dialogue [[Paper]](https://aclanthology.org/P07-1063/)
- **Humor and Wit**: Measure the chatbot's ability to inject humor and wit into conversations, mimicking human-like banter.
  1. Humor Recognition Using Deep Learning [[Paper]](https://aclanthology.org/N18-2018/)
  2. Humor Recognition and Humor Anchor Extraction [[Paper]](https://aclanthology.org/D15-1284/)
  3. How Did This Get Funded?! Automatically Identifying Quirky Scientific Achievements [[Paper]](https://aclanthology.org/2021.acl-long.2/)

### User Satisfaction Metrics:
- **User Ratings**: Collect user feedback through ratings or surveys to gauge satisfaction levels.
  1. RankME: Reliable Human Ratings for Natural Language Generation [[Paper]](https://aclanthology.org/N18-2012/)
  2. Modeling User Satisfaction Transitions in Dialogues from Overall Ratings [[Paper]](https://aclanthology.org/W10-4304/)

### Ethical and Fairness Metrics:
- **Bias Detection**: Evaluate the chatbot's susceptibility to biases in language generation or response selection.
  1. Mind Your Bias: A Critical Review of Bias Detection Methods for Contextual Language Models [[Paper]](https://aclanthology.org/2022.findings-emnlp.311/)
  2. Language-Agnostic Bias Detection in Language Models with Bias Probing [[Paper]](https://aclanthology.org/2023.findings-emnlp.848/)
- **Fairness**: Assess whether the chatbot treats all users fairly and avoids discrimination based on demographics or other factors.
  1. Fairness in Language Models Beyond English: Gaps and Challenges [[Paper]](https://aclanthology.org/2023.findings-eacl.157/)
  2. On the Intrinsic and Extrinsic Fairness Evaluation Metrics for Contextualized Language Representations [[Paper]](https://aclanthology.org/2022.acl-short.62/)
  3. Measuring Fairness with Biased Rulers: A Comparative Study on Bias Metrics for Pre-trained Language Models [[Paper]](https://aclanthology.org/2022.naacl-main.122/)
  4. Systematic Evaluation of Predictive Fairness [[Paper]](https://aclanthology.org/2022.aacl-main.6/)
  5. Your fairness may vary: Pretrained language model fairness in toxic text classification [[Paper]](https://aclanthology.org/2022.findings-acl.176/)

### Benchmarking Metrics:
- **Comparative Studies**: Compare the performance of the chatbot against other state-of-the-art models or human benchmarks.
  1. Counter Turing Test (CT2): AI-Generated Text Detection is Not as Easy as You May Think - Introducing AI Detectability Index (ADI) [[Paper]](https://aclanthology.org/2023.emnlp-main.136/)
  2. TURINGBENCH: A Benchmark Environment for Turing Test in the Age of Neural Text Generation [[Paper]](https://aclanthology.org/2021.findings-emnlp.172/)
  3. Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses [[Paper]](https://aclanthology.org/P17-1103/)
  4. On Degrees of Freedom in Defining and Testing Natural Language Understanding [[Paper]](https://aclanthology.org/2023.findings-acl.861/)

